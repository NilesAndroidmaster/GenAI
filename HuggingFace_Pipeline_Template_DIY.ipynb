{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using AutoModel"
      ],
      "metadata": {
        "id": "5ojqv1rAsjIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hByDmQUarfIN"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set the random seed for reproducibility\n",
        "# HINT: Use torch.random.manual_seed()"
      ],
      "metadata": {
        "id": "bM4A-QBWxBRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the model from Hugging Face\n",
        "# HINT: Use AutoModelForCausalLM.from_pretrained()\n",
        "# MODEL_NAME: \"microsoft/Phi-3-mini-4k-instruct\""
      ],
      "metadata": {
        "id": "n_xjCtZEsLVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the tokenizer for the model\n",
        "# HINT: Use AutoTokenizer.from_pretrained()"
      ],
      "metadata": {
        "id": "_h7YjJbEsMwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define the messages for the conversation\n",
        "# HINT: Create a list of dictionaries representing conversation history."
      ],
      "metadata": {
        "id": "2TVnDMh7sNk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create a pipeline for text generation\n",
        "# HINT: Use pipeline() with appropriate parameters for text-generation"
      ],
      "metadata": {
        "id": "oHi6B4WwsOpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define generation arguments\n",
        "# HINT: Set parameters like max_new_tokens, temperature, etc."
      ],
      "metadata": {
        "id": "0vF_wu9lsPdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Check how tokenizer works\n",
        "# HINT: use tokenizer"
      ],
      "metadata": {
        "id": "6usxlbrzsQS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Generate and print output using the pipeline\n",
        "# HINT: Pass the messages and generation_args to the pipeline."
      ],
      "metadata": {
        "id": "zmBnps7wsRAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add another conversation and test the model with different input.\n",
        "# HINT: Change the user input in the messages and call the pipeline again."
      ],
      "metadata": {
        "id": "a4dbxQ8qsSRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using pipeline"
      ],
      "metadata": {
        "id": "PlgV4pWDsodj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the text2text-generation pipeline with a different model (for translation).\n",
        "# HINT: Use \"snehalyelmati/mt5-hindi-to-english\""
      ],
      "metadata": {
        "id": "FrrreXKCsrjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass any hindi text to the pipeline"
      ],
      "metadata": {
        "id": "4wZ-FSoKssSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}